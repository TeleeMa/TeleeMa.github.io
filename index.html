<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="misc/UST.svg.png" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
<title>Teli Ma</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Teli Ma</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<!-- <div class="menu-item"><a href="experience.html">Experience</a></div> -->
<!-- <div class="menu-item"><a href="research.html">Research</a></div> -->
<!-- <div class="menu-item"><a href="awards.html">Awards</a></div> -->
<div class="menu-item"><a href="publications2.html">Publications</a></div>
<!-- <div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div> -->
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Home</h1>
</div>
</div>
<table class="imgtable" style="width: 100%; table-layout: fixed;"><tr><td style="text-align: center !important;  width: 40%; vertical-align: top;"><p><h1 style="margin: 0; padding: 0; font-size: 1.5em;"><b>Teli Ma</b></h1><br />
Ph.D. Student <br />
<a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/information-hub/artificial-intelligence/">AI Thrust,</a>
<a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/information-hub/">Infomation Hub</a> <br />
<a href="https://www.hkust-gz.edu.cn/">The Hong Kong University of Science and Technology, Guangzhou Campus</a></p>
<p>
Email: <a href="mailto:telima9868@gmail.com">telima9868@gmail.com</a>; <br> <a href="mailto:tma184@connect.hkust-gz.edu.cn">tma184@connect.hkust-gz.edu.cn</a><br />
</p>
<p><a href="https://scholar.google.com/citations?user=arny77IAAAAJ&hl=en&oi=ao">Google Scholar</a><br />
<a href="https://github.com/TeleeMa">Github</a><br />
<a href="https://www.linkedin.com/in/teli-ma-538a66127/">LinkedIn</a><br /></p>
</td>
<td style="width: 40%; vertical-align: top; padding-left: 40px; padding-top: 20px;">
<img src="misc/me_pidan.png" alt="alt text" width="250px" height="240px" />&nbsp; 
<!-- 155,210 -->
</td>
<td style="width: 40%; vertical-align: top; text-align: center !important;">
<p><h1 style="margin: 0; padding: 0; font-size: 1.5em;"><b>Pidan</b></h1><br />
My Cat <br />
Loves parkour and <br />
manipulating objects <br />
on the table</p>
<p>
I wish I could develop a robot that can do these things as efficiently as he does. <br>

</p>

</td>
</tr></table>
<h2>About Me</h2>
<p>Greetings! I am a Ph.D. student in Artificial Intelligence at HKUST, GZ, conducting research under the guidance of <a href="https://junweiliang.me/index.html">Prof. Junwei Liang</a>. 
  My research interests include <b>robotic learning</b> and <b>vision-language understanding</b>. </p>
  <p>Previously, I obtained my BSc degree from Honors College of Beihang University (BUAA) supervised by <a href="https://shi.buaa.edu.cn/mpl/en/index.htm">Prof. Baochang Zhang</a> 
  and <a href="https://cse.buffalo.edu/~doermann/">Prof. David Doermann</a> (from UB). 
  Also, I worked as a Research Engineer in <a href="https://opengvlab.shlab.org.cn/">OpenGVLab</a> of <a href="https://www.shlab.org.cn/">Shanghai AI Lab</a> 
  led by <a href="https://mmlab.siat.ac.cn/yuqiao/">Prof. Yu Qiao</a>, 
  under the supervision of <a href="https://gaopengcuhk.github.io/">Dr. Peng Gao</a> and <a href="https://www.ee.cuhk.edu.hk/~hsli/">Prof. Hongsheng Li</a>.
  </p>
  
<!-- <div class="infoblock">
<div class="blockcontent"> -->
<h2>News</h2>
<ul>
  <li><p><b>Aug. 2025:</b> <a href="https://teleema.github.io/projects/GLOVER++/">GLOVER++</a> and <a href="https://acodedog.github.io/OmniPerceptionPages/">OmniPerception</a> are accepted by CoRL 2025! <br></p></li>
  <li><p><b>Feb. 2025:</b> One paper accepted to CVPR 2025 [<a href="https://jiaming-zhou.github.io/projects/HumanRobotAlign/">project homepage</a>]. <br></p></li>
  <li><p><b>Sep. 2024:</b> One paper accepted to CoRL 2024 [<a href="projects/Sigma_Agent/index.html">project homepage</a>]. <br></p></li>
  <li><p><b>Mar. 2024:</b> One paper accepted to NAACL 2024 [<a href="projects/SADE/sade.html">project homepage</a>]. <br></p></li>
  <li><p><b>Oct. 2023:</b> Go to Paris for <a href="https://iccv2023.thecvf.com/main.conference.program-107.php">ICCV 2023</a>, nice trip!</a> <br></p></li>
  <li><p><b>Sep. 2023:</b> Nominated by the PCs as a reviewer of <a href="https://iclr.cc/">ICLR 2024</a>. <br></p></li>
  <li><p><b>Sep. 2023:</b> Honored to be the representative of new PG students at the <a href="misc/IMG_9738.JPG">orientation</a> of INFO Hub. <br></p></li>
  <li><p> <b>Aug. 2023:</b> <a href="https://arxiv.org/pdf/2110.04544.pdf">CLIP-Adapter</a> is accepted by IJCV finally. <br></p></li>
  <li><p><b>Jul. 2023:</b> One paper accepted to ICCV 2023 [<a href="https://arxiv.org/pdf/2308.12549.pdf">SyncTrack</a>]. <br></p></li> 
  <li><p><b>Nov. 2022:</b> One paper accepted to AAAI 2023 [<a href="https://arxiv.org/pdf/2302.00956.pdf">ReBNN</a> (<font color="red">oral</font>)]. <br></p></li> 
  <li><p><b>Oct. 2022:</b> <a href="https://bmvc2022.mpi-inf.mpg.de/0481.pdf">One paper</a> accepted to BMVC 2022. <br></p></li>
  <li><p><b>Oct. 2022:</b> One paper accepted to NeurIPS 2022 [<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/e7938ede51225b490bb69f7b361a9259-Paper-Conference.pdf">MCMAE/ConvMAE</a> (<font color="red">spotlight</font>, 3.7% acceptance rate, 384/10411)]. <br></p></li>
  <li><p><b>Jul. 2022:</b> Two papers accepted to ECCV 2022 [<a href="https://link.springer.com/chapter/10.1007/978-3-031-20083-0_21">IDa-Det</a>][<a href="https://link.springer.com/chapter/10.1007/978-3-031-20053-3_2">RBONNs</a> (<font color="red">oral</font>, 2.7% acceptance rate, 158/5803)]. <br></p></li> 
  <li><p><b>Oct. 2021:</b> One paper accepted to NeurIPS 2021 [<a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/d56b9fc4b0f1be8871f5e1c40c0067e7-Paper.pdf">DSNet</a>]. <br></p></li>
</ul>

<h2>Awards</h2>
<ul>
<li><p>PG scholarship of HKUST(GZ), 2023 <br></p></li>
<li><p>Excellent Intern Award of Baidu. Inc, 2021 <br></p></li>
<li><p>Outstanding Undergraduate Thesis of BUAA, 2020 <br></p></li>
<li><p>Honor Undergraduate Degree of BUAA, 2020 <br></p></li>
<li><p>Excellent Student Scholarship of BUAA, 2018
</p></li>
</ul>



<h2>Academic Services</h2>
<ul>
<li><p>Reviewer of AAAI2025, ICLR2025, ICML2025, ICCV2025, CoRL2025, RAL, NeurIPS2025<br></p></li> 
<li><p>Reviewer of ICLR2024, CVPR2024, ICML2024, ECCV2024, NeurIPS2024<br></p></li>
<li><p>Reviewer of CVPR2023, ICCV2023, NeurIPS2023<br></p></li>
<li><p>Emergency reviewer of CVPR2022<br></p></li>
</ul>

<h2>Teaching Assistant Experience</h2>
<ul>
<li><p><b>AIAA 5032 Foundations of Artificial Intelligence</b><br></p></li>
Spring, 2024, HKUST(GZ) <br>
Instructor: <a href="https://junweiliang.me/index.html">Dr. Junwei Liang</a>
</ul>

<ul>
<li><p><b>AIAA 2711 Mathematics for AI</b><br></p></li>
  Spring, 2025, HKUST(GZ) <br>
  Instructor: <a href="https://sss-cpslab.cn/">Dr. Bingzhuo Zhong</a>
</ul>

<!-- <h2>Miscellaneous</h2>
Outside of research, I enjoy traveling, photography, and ball gamesüéæüè∏.
<br>
I have a cute cat named <b>PiDan</b>. He loves parkour and manipulating objects on the table. 
<br>
I wish I could develop a robot that can do these things as efficiently as he does.
<br>
<br>
<img src="misc/pidan.jpg" alt="alt text" width="1200px" height="200px" />

<br> -->

</div></div>
</tr>
</table>
</body>
</html>